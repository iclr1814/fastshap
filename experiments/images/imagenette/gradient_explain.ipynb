{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sorted-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_v2_behavior()\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import shap\n",
    "import sys, os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from tensorflow.keras.layers import (Input, Layer, Dense)\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tf_explain.utils.image import transform_to_normalized_grayscale\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# IMPORTANT: SET RANDOM SEEDS FOR REPRODUCIBILITY\n",
    "os.environ['PYTHONHASHSEED'] = str(420)\n",
    "import random\n",
    "random.seed(420)\n",
    "np.random.seed(420)\n",
    "tf.random.set_seed(420)\n",
    "\n",
    "#Select GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-colon",
   "metadata": {},
   "source": [
    "## Load Images, Predictions, and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "natural-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = os.path.join(os.getcwd(), 'images')\n",
    "img = np.load(os.path.join(images_dir, 'processed_images.npy'), allow_pickle=True)\n",
    "labels = np.load(os.path.join(images_dir, 'labels.npy'), allow_pickle=True)\n",
    "preds = np.load(os.path.join(images_dir, 'predictions.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-queen",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gorgeous-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "INPUT_SHAPE = (224,224,3)\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=True, weights='imagenet', \n",
    "    input_shape=INPUT_SHAPE\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model_input = Input(shape=INPUT_SHAPE, dtype='float32', name='input')\n",
    "\n",
    "net = base_model(model_input)\n",
    "out = Dense(10, activation='softmax')(net)\n",
    "\n",
    "model = Model(model_input, out)\n",
    "\n",
    "model_weights_path = 'model/20210511_21_28_36/model_weights.h5'\n",
    "\n",
    "model.load_weights(model_weights_path)\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-claim",
   "metadata": {},
   "source": [
    "# Gradient Based Explainations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-campus",
   "metadata": {},
   "source": [
    "## Grad CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-separation",
   "metadata": {},
   "source": [
    "### Model Surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "typical-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_flat = Sequential()\n",
    "conv_model = Model(\n",
    "    model.input, model.layers[1].get_layer('conv5_block3_out').get_output_at(1)\n",
    ")\n",
    "model_flat.add(conv_model)\n",
    "model_flat.add(model.layers[1].get_layer('avg_pool'))\n",
    "model_flat.add(model.layers[1].get_layer('predictions'))\n",
    "model_flat.add(model.layers[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-correspondence",
   "metadata": {},
   "source": [
    "### Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "illegal-public",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff63528ce65d4175905b125af1802124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tf_explain.core.grad_cam import GradCAM\n",
    "import cv2\n",
    "\n",
    "gcam = GradCAM()\n",
    "layer_name = gcam.infer_grad_cam_target_layer(model_flat)\n",
    "cams = []\n",
    "t = time.time()\n",
    "grad_model = tf.keras.models.Model(\n",
    "    model_flat.inputs, [model_flat.get_layer(layer_name).get_output_at(0), model_flat.output]\n",
    ")\n",
    "\n",
    "cams = []\n",
    "for i in tqdm(range(20)): #mini-batch\n",
    "    with tf.GradientTape() as tape:\n",
    "        inputs = tf.cast(img[i*50:(i+1)*50], tf.float32)\n",
    "        tape.watch(inputs)\n",
    "        conv_outputs, predictions = grad_model(inputs)\n",
    "        loss = K.max(predictions, 1)\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    grads = (\n",
    "        tf.cast(conv_outputs > 0, \"float32\")\n",
    "        * tf.cast(grads > 0, \"float32\")\n",
    "        * grads\n",
    "    )\n",
    "    \n",
    "    cam = tf.stack(GradCAM.generate_ponderated_output(conv_outputs, grads))\n",
    "    cams.append(cam)\n",
    "    \n",
    "cams = np.array([cv2.resize(cam, (224, 224)) for cam in tf.concat(cams, 0).numpy()])\n",
    "\n",
    "explaining_time = time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "retired-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'gradcam'\n",
    "model_dir = os.path.join(os.getcwd(), save_dir)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "cams.dump(os.path.join(model_dir, 'explanations.npy'))\n",
    "\n",
    "with open(os.path.join(model_dir, 'explaining_time.pkl'), 'wb') as f:\n",
    "    pickle.dump(explaining_time, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-cornwall",
   "metadata": {},
   "source": [
    "## SmoothGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "modern-brook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075cbc5126bf406fb27f82c1c4953b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tf_explain.core.smoothgrad import SmoothGrad\n",
    "import itertools\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "smoothgrads = []\n",
    "for i in tqdm(range(100)):\n",
    "    sg = SmoothGrad()\n",
    "    num_samples = 5\n",
    "    noisy_images = sg.generate_noisy_images(img[i*10:(i+1)*10], num_samples=num_samples, noise=1.0)\n",
    "\n",
    "    expected_output = tf.one_hot(\n",
    "        list(itertools.chain(*[[yp.argmax()] * num_samples for yp in preds[i*10:(i+1)*10]])),\n",
    "        10,\n",
    "        on_value=None,\n",
    "        off_value=None,\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        inputs = tf.cast(noisy_images, tf.float32)\n",
    "        tape.watch(inputs)\n",
    "        predictions = model(inputs)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(\n",
    "            expected_output, predictions\n",
    "        )\n",
    "\n",
    "    grads = tape.gradient(loss, inputs)\n",
    "\n",
    "    grads_per_image = tf.reshape(grads, (-1, num_samples, *grads.shape[1:]))\n",
    "    smoothed_gradients = tf.reduce_mean(grads_per_image, axis=1)\n",
    "\n",
    "    grayscale_gradients = transform_to_normalized_grayscale(\n",
    "            tf.abs(smoothed_gradients)\n",
    "        ).numpy()\n",
    "\n",
    "    smoothgrads.append(grayscale_gradients)\n",
    "    \n",
    "explaining_time = time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conservative-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'smoothgrad'\n",
    "model_dir = os.path.join(os.getcwd(), save_dir)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "smoothgrads = np.vstack(smoothgrads)\n",
    "smoothgrads.dump(os.path.join(model_dir, 'explanations.npy'))\n",
    "\n",
    "with open(os.path.join(model_dir, 'explaining_time.pkl'), 'wb') as f:\n",
    "    pickle.dump(explaining_time, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-macedonia",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "athletic-conditions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1f9d386c484596b10b17918c2985b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tf_explain.core.integrated_gradients import IntegratedGradients\n",
    "\n",
    "t = time.time()\n",
    "igrads = []\n",
    "n_steps = 10\n",
    "for i in tqdm(range(200)): #mini-batch\n",
    "    ig = IntegratedGradients()\n",
    "    interpolated_images = ig.generate_interpolations(\n",
    "            img[i*5:(i+1)*5], n_steps=n_steps\n",
    "        )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        inputs = tf.cast(interpolated_images, tf.float32)\n",
    "        tape.watch(inputs)\n",
    "        predictions = model(inputs)\n",
    "        loss = K.max(predictions, 1)\n",
    "\n",
    "    grads = tape.gradient(loss, inputs)\n",
    "    grads_per_image = tf.reshape(grads, (-1, n_steps, *grads.shape[1:]))\n",
    "\n",
    "    integrated_gradients = tf.reduce_mean(grads_per_image, axis=1)\n",
    "\n",
    "    grayscale_integrated_gradients = transform_to_normalized_grayscale(\n",
    "            tf.abs(integrated_gradients)\n",
    "        ).numpy()\n",
    "\n",
    "    igrads.append(grayscale_integrated_gradients)\n",
    "\n",
    "    \n",
    "explaining_time = time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "destroyed-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'integratedgradients'\n",
    "model_dir = os.path.join(os.getcwd(), save_dir)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "igrads = np.vstack(igrads)\n",
    "igrads.dump(os.path.join(model_dir, 'explanations.npy'))\n",
    "\n",
    "with open(os.path.join(model_dir, 'explaining_time.pkl'), 'wb') as f:\n",
    "    pickle.dump(explaining_time, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-deposit",
   "metadata": {},
   "source": [
    "## SHAP Deep Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "international-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/data/paulab/miniconda3/envs/tf23/lib/python3.7/site-packages/shap/explainers/tf_utils.py:28: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras is no longer supported, please use tf.keras instead.\n"
     ]
    }
   ],
   "source": [
    "import shap \n",
    "deepshap = shap.DeepExplainer(model=model, \n",
    "                              data=np.expand_dims(np.zeros_like(img[0]), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "activated-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "shap_values = deepshap.shap_values(img)\n",
    "explaining_time = time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faced-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'deepshap'\n",
    "model_dir = os.path.join(os.getcwd(), save_dir)\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "with open(os.path.join(model_dir, 'explaining_time.pkl'), 'wb') as f:\n",
    "    pickle.dump(explaining_time, f)\n",
    "    \n",
    "with open(os.path.join(model_dir, 'shap_values.pkl'), 'wb') as f:\n",
    "    pickle.dump(shap_values, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
