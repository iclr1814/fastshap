{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interesting-finance",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mature-desert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "played-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe\n",
    "df = pd.read_csv('../data/OnlineNewsPopularity.csv', header=0, sep=', ', engine='python')\n",
    "\n",
    "# Drop columns\n",
    "df.drop(columns=['url', 'timedelta'], inplace=True)\n",
    "\n",
    "# Binarize target column\n",
    "df['shares'] = df['shares'].values > 1400\n",
    "\n",
    "# Split into X, Y\n",
    "values = df.values.astype(float)\n",
    "X_cols = np.array(df.columns) != 'shares'\n",
    "X, Y = values[:, X_cols], values[:, ~X_cols]\n",
    "feature_names = np.array(df.columns)[X_cols]\n",
    "num_features = X.shape[1]\n",
    "\n",
    "# Train/val/test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=123)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entitled-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize continuous columns\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train = ss.transform(X_train)\n",
    "X_val = ss.transform(X_val)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-barcelona",
   "metadata": {},
   "source": [
    "# Set up imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "angry-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fastshap_torch\n",
    "from fastshap_torch import Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "another-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', 4)\n",
    "surrogate = torch.load('../models/news_surrogate.pt').eval().to(device)\n",
    "num_features = X_train.shape[1]\n",
    "surr = Surrogate(surrogate, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-taylor",
   "metadata": {},
   "source": [
    "# FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "endless-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastshap_torch import FastSHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-palace",
   "metadata": {},
   "source": [
    "# Test samples number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distant-biography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.01873461\n",
      "Best val loss = 0.00275944\n",
      "Best val loss = 0.00032966\n",
      "Best val loss = 0.00032586\n",
      "Best val loss = 0.00032560\n",
      "Best val loss = 0.00032520\n",
      "Best val loss = 0.00032291\n"
     ]
    }
   ],
   "source": [
    "for n_samples in (1, 4, 16, 32, 48, 64, 96):\n",
    "    # Set up explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP wrapper\n",
    "    fastshap = FastSHAP(explainer, surr, normalization='additive', link=nn.Softmax(dim=1))\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        X_train,\n",
    "        X_val[:500],\n",
    "        batch_size=32,\n",
    "        num_samples=n_samples,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=0,\n",
    "        paired_sampling=False,\n",
    "        validation_samples=128,\n",
    "        validation_seed=123,\n",
    "        lookback=5,\n",
    "        verbose=False)\n",
    "\n",
    "    # Print performance\n",
    "    print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    modifier = 'samples={}'.format(n_samples)\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, '../models/news_explainer {} nopenalty.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fifth-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00270184\n",
      "Best val loss = 0.00032815\n",
      "Best val loss = 0.00032703\n",
      "Best val loss = 0.00032261\n",
      "Best val loss = 0.00032042\n",
      "Best val loss = 0.00032073\n"
     ]
    }
   ],
   "source": [
    "for n_samples in (4, 16, 32, 48, 64, 96):\n",
    "    # Set up explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP wrapper\n",
    "    fastshap = FastSHAP(explainer, surr, normalization='additive', link=nn.Softmax(dim=1))\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        X_train,\n",
    "        X_val[:500],\n",
    "        batch_size=32,\n",
    "        num_samples=n_samples,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=0,\n",
    "        paired_sampling=True,\n",
    "        validation_samples=128,\n",
    "        validation_seed=123,\n",
    "        lookback=5,\n",
    "        verbose=False)\n",
    "\n",
    "    # Print performance\n",
    "    print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    modifier = 'paired_samples={}'.format(n_samples)\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, '../models/news_explainer {} nopenalty.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-roads",
   "metadata": {},
   "source": [
    "# Test other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "angry-bikini",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00032219\n"
     ]
    }
   ],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, surr, normalization='additive', link=nn.Softmax(dim=1))\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_val[:500],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=123,\n",
    "    lookback=5,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nopenalty'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/news_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continuous-portland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00031003\n"
     ]
    }
   ],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, surr, normalization=None, link=nn.Softmax(dim=1))\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_val[:500],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0.1,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=123,\n",
    "    lookback=5,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nonormalization'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/news_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wound-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00030896\n"
     ]
    }
   ],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, surr, normalization=None, link=nn.Softmax(dim=1))\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_val[:500],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=123,\n",
    "    lookback=5,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nopenalty nonormalization'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/news_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-fruit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
