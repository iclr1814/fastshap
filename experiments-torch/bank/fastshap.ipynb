{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lined-agriculture",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "internal-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gorgeous-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = sage.datasets.bank()\n",
    "\n",
    "# Convert binary features to 0/1\n",
    "binary_cols = ['Default', 'Housing', 'Loan']\n",
    "for col in binary_cols:\n",
    "    df[col] = (df[col] == 'yes').astype(float)\n",
    "    \n",
    "# Convert education to numerical\n",
    "df['Education'].replace(\n",
    "    {'unknown': 0, 'primary': 1, 'secondary': 2, 'tertiary': 3},\n",
    "    inplace=True)\n",
    "\n",
    "# Convert month to numerical\n",
    "df['Month'].replace(\n",
    "    {'jan': 0, 'feb': 1, 'mar': 2, 'apr': 3, 'may': 4, 'jun': 5,\n",
    "     'jul': 6, 'aug': 7, 'sep': 8, 'oct': 9, 'nov': 10, 'dec': 11},\n",
    "    inplace=True)\n",
    "\n",
    "# Convert marital to one-hot\n",
    "for value in np.unique(df['Marital'].values):\n",
    "    df['Marital-{}'.format(value)] = (df['Marital'] == value).astype(float)\n",
    "df.drop(columns='Marital', inplace=True)\n",
    "\n",
    "# Convert contact to one-hot\n",
    "for value in np.unique(df['Contact'].values):\n",
    "    df['Contact-{}'.format(value)] = (df['Contact'] == value).astype(float)\n",
    "df.drop(columns='Contact', inplace=True)\n",
    "\n",
    "# Convert prev outcome to one-hot\n",
    "for value in np.unique(df['Prev Outcome'].values):\n",
    "    df['Prev Outcome-{}'.format(value)] = (df['Prev Outcome'] == value).astype(float)\n",
    "df.drop(columns='Prev Outcome', inplace=True)\n",
    "\n",
    "# Convert job to one-hot\n",
    "for value in np.unique(df['Job'].values):\n",
    "    df['Job-{}'.format(value)] = (df['Job'] == value).astype(float)\n",
    "df.drop(columns='Job', inplace=True)\n",
    "\n",
    "# Split into X, Y\n",
    "values = df.values.astype(float)\n",
    "X_cols = np.array(df.columns) != 'Success'\n",
    "X, Y = values[:, X_cols], values[:, ~X_cols]\n",
    "\n",
    "# Get feature names, groups\n",
    "feature_names = np.array(df.columns)[X_cols]\n",
    "prefixes = np.array([name.split('-')[0] for name in feature_names])\n",
    "groups = []\n",
    "group_names = []\n",
    "for prefix in np.unique(prefixes):\n",
    "    groups.append(np.where(prefixes == prefix)[0])\n",
    "    group_names.append(prefix)\n",
    "\n",
    "# Train/val/test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=123)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "competitive-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize continuous columns\n",
    "feature_names = list(feature_names)\n",
    "num_features = len(feature_names)\n",
    "continuous_cols = ['Age', 'Balance', 'Day', 'Duration', 'Campaign',\n",
    "                   'Month', 'Prev Days', 'Prev Contacts']\n",
    "continuous_inds = [feature_names.index(col) for col in continuous_cols]\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train[:, continuous_inds])\n",
    "X_train[:, continuous_inds] = ss.transform(X_train[:, continuous_inds])\n",
    "X_val[:, continuous_inds] = ss.transform(X_val[:, continuous_inds])\n",
    "X_test[:, continuous_inds] = ss.transform(X_test[:, continuous_inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-trauma",
   "metadata": {},
   "source": [
    "# Set up imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "practical-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fastshap_torch\n",
    "from fastshap_torch import Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mighty-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', 5)\n",
    "surrogate = torch.load('../models/bank_surrogate.pt').eval().to(device)\n",
    "num_features = X_train.shape[1]\n",
    "surr = Surrogate(surrogate, num_features, groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-lithuania",
   "metadata": {},
   "source": [
    "# FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amber-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastshap_torch import FastSHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-image",
   "metadata": {},
   "source": [
    "# Test samples number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lyric-permission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00311171\n",
      "Best val loss = 0.00047078\n",
      "Best val loss = 0.00005620\n",
      "Best val loss = 0.00005627\n",
      "Best val loss = 0.00005515\n",
      "Best val loss = 0.00005536\n",
      "Best val loss = 0.00005495\n"
     ]
    }
   ],
   "source": [
    "for n_samples in (1, 4, 16, 32, 48, 64, 96):\n",
    "    # Set up explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 2 * len(groups))).to(device)\n",
    "\n",
    "    # Set up FastSHAP wrapper\n",
    "    fastshap = FastSHAP(explainer, surr, normalization='additive', link=nn.Softmax(dim=-1))\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        X_train,\n",
    "        X_val[:500],\n",
    "        batch_size=32,\n",
    "        num_samples=n_samples,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=0,\n",
    "        paired_sampling=False,\n",
    "        validation_samples=128,\n",
    "        validation_seed=123,\n",
    "        verbose=False)\n",
    "\n",
    "    # Print performance\n",
    "    print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    modifier = 'samples={}'.format(n_samples)\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, '../models/bank_explainer {} nopenalty.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "blocked-metadata",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00046258\n",
      "Best val loss = 0.00005534\n",
      "Best val loss = 0.00005523\n",
      "Best val loss = 0.00005464\n",
      "Best val loss = 0.00005514\n",
      "Best val loss = 0.00005465\n"
     ]
    }
   ],
   "source": [
    "for n_samples in (4, 16, 32, 48, 64, 96):\n",
    "    # Set up explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 2 * len(groups))).to(device)\n",
    "\n",
    "    # Set up FastSHAP wrapper\n",
    "    fastshap = FastSHAP(explainer, surr, normalization='additive', link=nn.Softmax(dim=-1))\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        X_train,\n",
    "        X_val[:500],\n",
    "        batch_size=32,\n",
    "        num_samples=n_samples,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=0,\n",
    "        paired_sampling=True,\n",
    "        validation_samples=128,\n",
    "        validation_seed=123,\n",
    "        verbose=False)\n",
    "\n",
    "    # Print performance\n",
    "    print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    modifier = 'paired_samples={}'.format(n_samples)\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, '../models/bank_explainer {} nopenalty.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-cleaners",
   "metadata": {},
   "source": [
    "# Test other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "worth-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * len(groups))).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, surr, normalization='additive', link=nn.Softmax(dim=-1))\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_val[:500],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=123,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nopenalty'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/bank_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "primary-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * len(groups))).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, surr, normalization=None, link=nn.Softmax(dim=-1))\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_val[:500],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0.1,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=123,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nonormalization'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/bank_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sought-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * len(groups))).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, surr, normalization=None, link=nn.Softmax(dim=-1))\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_val[:500],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=123,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nopenalty nonormalization'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/bank_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-invention",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
