{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "peaceful-intro",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sustained-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "technological-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = sage.datasets.bank()\n",
    "\n",
    "# Convert binary features to 0/1\n",
    "binary_cols = ['Default', 'Housing', 'Loan']\n",
    "for col in binary_cols:\n",
    "    df[col] = (df[col] == 'yes').astype(float)\n",
    "    \n",
    "# Convert education to numerical\n",
    "df['Education'].replace(\n",
    "    {'unknown': 0, 'primary': 1, 'secondary': 2, 'tertiary': 3},\n",
    "    inplace=True)\n",
    "\n",
    "# Convert month to numerical\n",
    "df['Month'].replace(\n",
    "    {'jan': 0, 'feb': 1, 'mar': 2, 'apr': 3, 'may': 4, 'jun': 5,\n",
    "     'jul': 6, 'aug': 7, 'sep': 8, 'oct': 9, 'nov': 10, 'dec': 11},\n",
    "    inplace=True)\n",
    "\n",
    "# Convert marital to one-hot\n",
    "for value in np.unique(df['Marital'].values):\n",
    "    df['Marital-{}'.format(value)] = (df['Marital'] == value).astype(float)\n",
    "df.drop(columns='Marital', inplace=True)\n",
    "\n",
    "# Convert contact to one-hot\n",
    "for value in np.unique(df['Contact'].values):\n",
    "    df['Contact-{}'.format(value)] = (df['Contact'] == value).astype(float)\n",
    "df.drop(columns='Contact', inplace=True)\n",
    "\n",
    "# Convert prev outcome to one-hot\n",
    "for value in np.unique(df['Prev Outcome'].values):\n",
    "    df['Prev Outcome-{}'.format(value)] = (df['Prev Outcome'] == value).astype(float)\n",
    "df.drop(columns='Prev Outcome', inplace=True)\n",
    "\n",
    "# Convert job to one-hot\n",
    "for value in np.unique(df['Job'].values):\n",
    "    df['Job-{}'.format(value)] = (df['Job'] == value).astype(float)\n",
    "df.drop(columns='Job', inplace=True)\n",
    "\n",
    "# Split into X, Y\n",
    "values = df.values.astype(float)\n",
    "X_cols = np.array(df.columns) != 'Success'\n",
    "X, Y = values[:, X_cols], values[:, ~X_cols]\n",
    "\n",
    "# Get feature names, groups\n",
    "feature_names = np.array(df.columns)[X_cols]\n",
    "prefixes = np.array([name.split('-')[0] for name in feature_names])\n",
    "groups = []\n",
    "group_names = []\n",
    "for prefix in np.unique(prefixes):\n",
    "    groups.append(np.where(prefixes == prefix)[0])\n",
    "    group_names.append(prefix)\n",
    "\n",
    "# Train/val/test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=123)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "digital-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize continuous columns\n",
    "feature_names = list(feature_names)\n",
    "num_features = len(feature_names)\n",
    "continuous_cols = ['Age', 'Balance', 'Day', 'Duration', 'Campaign',\n",
    "                   'Month', 'Prev Days', 'Prev Contacts']\n",
    "continuous_inds = [feature_names.index(col) for col in continuous_cols]\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train[:, continuous_inds])\n",
    "X_train[:, continuous_inds] = ss.transform(X_train[:, continuous_inds])\n",
    "X_val[:, continuous_inds] = ss.transform(X_val[:, continuous_inds])\n",
    "X_test[:, continuous_inds] = ss.transform(X_test[:, continuous_inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-drilling",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alpine-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import RandomSampler, BatchSampler\n",
    "from madgrad import MADGRAD\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gentle-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X_train_pt = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_pt = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_pt = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_train_pt = torch.tensor(Y_train, dtype=torch.float32)\n",
    "Y_val_pt = torch.tensor(Y_val, dtype=torch.float32)\n",
    "Y_test_pt = torch.tensor(Y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "settled-mother",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch = 1 -----\n",
      "Val loss = 0.2396\n",
      "\n",
      "New best epoch, loss = 0.2396\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.2324\n",
      "\n",
      "New best epoch, loss = 0.2324\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.2311\n",
      "\n",
      "New best epoch, loss = 0.2311\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.2321\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.2290\n",
      "\n",
      "New best epoch, loss = 0.2290\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.2246\n",
      "\n",
      "New best epoch, loss = 0.2246\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.2239\n",
      "\n",
      "New best epoch, loss = 0.2239\n",
      "\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.2226\n",
      "\n",
      "New best epoch, loss = 0.2226\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.2285\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.2216\n",
      "\n",
      "New best epoch, loss = 0.2216\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.2222\n",
      "\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.2226\n",
      "\n",
      "----- Epoch = 13 -----\n",
      "Val loss = 0.2200\n",
      "\n",
      "New best epoch, loss = 0.2200\n",
      "\n",
      "----- Epoch = 14 -----\n",
      "Val loss = 0.2145\n",
      "\n",
      "New best epoch, loss = 0.2145\n",
      "\n",
      "----- Epoch = 15 -----\n",
      "Val loss = 0.2154\n",
      "\n",
      "----- Epoch = 16 -----\n",
      "Val loss = 0.2167\n",
      "\n",
      "----- Epoch = 17 -----\n",
      "Val loss = 0.2143\n",
      "\n",
      "New best epoch, loss = 0.2143\n",
      "\n",
      "----- Epoch = 18 -----\n",
      "Val loss = 0.2172\n",
      "\n",
      "----- Epoch = 19 -----\n",
      "Val loss = 0.2154\n",
      "\n",
      "----- Epoch = 20 -----\n",
      "Val loss = 0.2161\n",
      "\n",
      "----- Epoch = 21 -----\n",
      "Val loss = 0.2172\n",
      "\n",
      "----- Epoch = 22 -----\n",
      "Val loss = 0.2176\n",
      "\n",
      "----- Epoch = 23 -----\n",
      "Val loss = 0.2145\n",
      "\n",
      "----- Epoch = 24 -----\n",
      "Val loss = 0.2155\n",
      "\n",
      "----- Epoch = 25 -----\n",
      "Val loss = 0.2212\n",
      "\n",
      "----- Epoch = 26 -----\n",
      "Val loss = 0.2248\n",
      "\n",
      "----- Epoch = 27 -----\n",
      "Val loss = 0.2243\n",
      "\n",
      "Stopping early\n"
     ]
    }
   ],
   "source": [
    "# Set up model\n",
    "device = torch.device('cuda', 6)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 1)).to(device)\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "max_epochs = 100\n",
    "lr = 1e-4\n",
    "lookback = 10\n",
    "validation_batch_size = 1000\n",
    "verbose = True\n",
    "\n",
    "# Set up train data loader\n",
    "train_set = TensorDataset(X_train_pt, Y_train_pt)\n",
    "random_sampler = RandomSampler(\n",
    "    train_set, replacement=True,\n",
    "    num_samples=int(np.ceil(len(X_train) / batch_size))*batch_size)\n",
    "batch_sampler = BatchSampler(\n",
    "    random_sampler, batch_size=batch_size, drop_last=True)\n",
    "train_loader = DataLoader(train_set, batch_sampler=batch_sampler)\n",
    "\n",
    "# Prepare validation dataset\n",
    "val_set = TensorDataset(X_val_pt, Y_val_pt)\n",
    "val_loader = DataLoader(val_set, batch_size=validation_batch_size)\n",
    "\n",
    "def validate(model, loader, loss_fn):\n",
    "    with torch.no_grad():\n",
    "        # Setup.\n",
    "        device = next(model.parameters()).device\n",
    "        mean_loss = 0\n",
    "        N = 0\n",
    "\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            N += len(x)\n",
    "            mean_loss += len(x) * (loss - mean_loss) / N\n",
    "\n",
    "    return mean_loss\n",
    "\n",
    "# Setup for training\n",
    "device = next(model.parameters()).device\n",
    "optimizer = MADGRAD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "best_loss = np.inf\n",
    "best_epoch = 0\n",
    "best_model = None\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # Prepare data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Make predictions\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Optimizer step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "\n",
    "    # Print progress\n",
    "    val_loss = validate(model, val_loader, loss_fn).item()\n",
    "    loss_list.append(val_loss)\n",
    "    if verbose:\n",
    "        print('----- Epoch = {} -----'.format(epoch + 1))\n",
    "        print('Val loss = {:.4f}'.format(val_loss))\n",
    "        print('')\n",
    "\n",
    "    # Check if best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model = deepcopy(model)\n",
    "        best_epoch = epoch\n",
    "        if verbose:\n",
    "            print('New best epoch, loss = {:.4f}'.format(val_loss))\n",
    "            print('')\n",
    "    elif epoch - best_epoch == lookback:\n",
    "        if verbose:\n",
    "            print('Stopping early')\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "for param, best_param in zip(model.parameters(),\n",
    "                             best_model.parameters()):\n",
    "    param.data = best_param.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dominican-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.eval()\n",
    "model.cpu()\n",
    "torch.save(model, '../models/bank_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-velvet",
   "metadata": {},
   "source": [
    "# Train surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loose-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastshap_torch.utils import MaskLayer1d\n",
    "from fastshap_torch import Surrogate, SoftCrossEntropyLoss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ethical-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "Y_train_surrogate = model(X_train_pt.to(device=device)).sigmoid().cpu().data.numpy()\n",
    "Y_train_surrogate = np.concatenate([1 - Y_train_surrogate, Y_train_surrogate], axis=1)\n",
    "Y_val_surrogate = model(X_val_pt.to(device=device)).sigmoid().cpu().data.numpy()\n",
    "Y_val_surrogate = np.concatenate([1 - Y_val_surrogate, Y_val_surrogate], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "religious-feeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss given no information = 0.3657\n"
     ]
    }
   ],
   "source": [
    "# Get loss upper bound\n",
    "p = Y_train_surrogate.mean(axis=0)\n",
    "soft_ce = - np.mean(np.sum(np.log(p) * Y_train_surrogate, axis=1))\n",
    "print('Loss given no information = {:.4f}'.format(soft_ce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "palestinian-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device('cuda', 6)\n",
    "\n",
    "# Create model\n",
    "surrogate = nn.Sequential(\n",
    "    MaskLayer1d(value=0, append=True),\n",
    "    nn.Linear(2 * num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2)).to(device)\n",
    "\n",
    "# Set up surrogate object\n",
    "surr = Surrogate(surrogate, num_features, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stuffed-coral",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Epoch = 1 -----\n",
      "Val loss = 0.2920\n",
      "\n",
      "New best epoch, loss = 0.2920\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.2870\n",
      "\n",
      "New best epoch, loss = 0.2870\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.2839\n",
      "\n",
      "New best epoch, loss = 0.2839\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.2831\n",
      "\n",
      "New best epoch, loss = 0.2831\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.2831\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.2805\n",
      "\n",
      "New best epoch, loss = 0.2805\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.2802\n",
      "\n",
      "New best epoch, loss = 0.2802\n",
      "\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.2807\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.2787\n",
      "\n",
      "New best epoch, loss = 0.2787\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.2798\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.2787\n",
      "\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.2784\n",
      "\n",
      "New best epoch, loss = 0.2784\n",
      "\n",
      "----- Epoch = 13 -----\n",
      "Val loss = 0.2785\n",
      "\n",
      "----- Epoch = 14 -----\n",
      "Val loss = 0.2780\n",
      "\n",
      "New best epoch, loss = 0.2780\n",
      "\n",
      "----- Epoch = 15 -----\n",
      "Val loss = 0.2781\n",
      "\n",
      "----- Epoch = 16 -----\n",
      "Val loss = 0.2784\n",
      "\n",
      "----- Epoch = 17 -----\n",
      "Val loss = 0.2780\n",
      "\n",
      "New best epoch, loss = 0.2780\n",
      "\n",
      "----- Epoch = 18 -----\n",
      "Val loss = 0.2773\n",
      "\n",
      "New best epoch, loss = 0.2773\n",
      "\n",
      "----- Epoch = 19 -----\n",
      "Val loss = 0.2790\n",
      "\n",
      "----- Epoch = 20 -----\n",
      "Val loss = 0.2776\n",
      "\n",
      "----- Epoch = 21 -----\n",
      "Val loss = 0.2775\n",
      "\n",
      "----- Epoch = 22 -----\n",
      "Val loss = 0.2770\n",
      "\n",
      "New best epoch, loss = 0.2770\n",
      "\n",
      "----- Epoch = 23 -----\n",
      "Val loss = 0.2772\n",
      "\n",
      "----- Epoch = 24 -----\n",
      "Val loss = 0.2774\n",
      "\n",
      "----- Epoch = 25 -----\n",
      "Val loss = 0.2768\n",
      "\n",
      "New best epoch, loss = 0.2768\n",
      "\n",
      "----- Epoch = 26 -----\n",
      "Val loss = 0.2767\n",
      "\n",
      "New best epoch, loss = 0.2767\n",
      "\n",
      "----- Epoch = 27 -----\n",
      "Val loss = 0.2772\n",
      "\n",
      "----- Epoch = 28 -----\n",
      "Val loss = 0.2767\n",
      "\n",
      "----- Epoch = 29 -----\n",
      "Val loss = 0.2774\n",
      "\n",
      "----- Epoch = 30 -----\n",
      "Val loss = 0.2767\n",
      "\n",
      "----- Epoch = 31 -----\n",
      "Val loss = 0.2774\n",
      "\n",
      "Stopping early\n",
      "Best loss = 0.2767\n",
      "----- Epoch = 1 -----\n",
      "Val loss = 0.2758\n",
      "\n",
      "New best epoch, loss = 0.2758\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.2757\n",
      "\n",
      "New best epoch, loss = 0.2757\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.2757\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.2758\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.2763\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.2754\n",
      "\n",
      "New best epoch, loss = 0.2754\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.2753\n",
      "\n",
      "New best epoch, loss = 0.2753\n",
      "\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.2754\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.2756\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.2755\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.2755\n",
      "\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.2761\n",
      "\n",
      "Stopping early\n",
      "Best loss = 0.2753\n",
      "----- Epoch = 1 -----\n",
      "Val loss = 0.2753\n",
      "\n",
      "New best epoch, loss = 0.2753\n",
      "\n",
      "----- Epoch = 2 -----\n",
      "Val loss = 0.2752\n",
      "\n",
      "New best epoch, loss = 0.2752\n",
      "\n",
      "----- Epoch = 3 -----\n",
      "Val loss = 0.2752\n",
      "\n",
      "----- Epoch = 4 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "New best epoch, loss = 0.2751\n",
      "\n",
      "----- Epoch = 5 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "New best epoch, loss = 0.2751\n",
      "\n",
      "----- Epoch = 6 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "----- Epoch = 7 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "----- Epoch = 8 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "----- Epoch = 9 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "New best epoch, loss = 0.2751\n",
      "\n",
      "----- Epoch = 10 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "New best epoch, loss = 0.2751\n",
      "\n",
      "----- Epoch = 11 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "----- Epoch = 12 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "----- Epoch = 13 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "New best epoch, loss = 0.2750\n",
      "\n",
      "----- Epoch = 14 -----\n",
      "Val loss = 0.2751\n",
      "\n",
      "----- Epoch = 15 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "New best epoch, loss = 0.2750\n",
      "\n",
      "----- Epoch = 16 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "----- Epoch = 17 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "New best epoch, loss = 0.2750\n",
      "\n",
      "----- Epoch = 18 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "----- Epoch = 19 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "----- Epoch = 20 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "----- Epoch = 21 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "New best epoch, loss = 0.2750\n",
      "\n",
      "----- Epoch = 22 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "----- Epoch = 23 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "----- Epoch = 24 -----\n",
      "Val loss = 0.2749\n",
      "\n",
      "New best epoch, loss = 0.2749\n",
      "\n",
      "----- Epoch = 25 -----\n",
      "Val loss = 0.2749\n",
      "\n",
      "New best epoch, loss = 0.2749\n",
      "\n",
      "----- Epoch = 26 -----\n",
      "Val loss = 0.2749\n",
      "\n",
      "----- Epoch = 27 -----\n",
      "Val loss = 0.2749\n",
      "\n",
      "----- Epoch = 28 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "----- Epoch = 29 -----\n",
      "Val loss = 0.2749\n",
      "\n",
      "----- Epoch = 30 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "New best epoch, loss = 0.2748\n",
      "\n",
      "----- Epoch = 31 -----\n",
      "Val loss = 0.2749\n",
      "\n",
      "----- Epoch = 32 -----\n",
      "Val loss = 0.2749\n",
      "\n",
      "----- Epoch = 33 -----\n",
      "Val loss = 0.2749\n",
      "\n",
      "----- Epoch = 34 -----\n",
      "Val loss = 0.2750\n",
      "\n",
      "----- Epoch = 35 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "New best epoch, loss = 0.2748\n",
      "\n",
      "----- Epoch = 36 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "----- Epoch = 37 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "----- Epoch = 38 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "----- Epoch = 39 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "New best epoch, loss = 0.2748\n",
      "\n",
      "----- Epoch = 40 -----\n",
      "Val loss = 0.2749\n",
      "\n",
      "----- Epoch = 41 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "----- Epoch = 42 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "----- Epoch = 43 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "----- Epoch = 44 -----\n",
      "Val loss = 0.2748\n",
      "\n",
      "Stopping early\n",
      "Best loss = 0.2748\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for batch_size in (32, 512, 8192):\n",
    "    surr.train((X_train, Y_train_surrogate),\n",
    "               (X_val, Y_val_surrogate),\n",
    "               batch_size=batch_size,\n",
    "               max_epochs=100,\n",
    "               loss_fn=SoftCrossEntropyLoss(),\n",
    "               validation_samples=50,\n",
    "               validation_batch_size=10000,\n",
    "               validation_seed=0,\n",
    "               verbose=True)\n",
    "    \n",
    "    print('Best loss = {:.4f}'.format(min(surr.loss_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "supported-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.cpu()\n",
    "surrogate.eval()\n",
    "torch.save(surrogate, '../models/bank_surrogate.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-spice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
