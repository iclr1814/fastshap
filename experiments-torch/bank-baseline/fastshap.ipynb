{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "analyzed-pricing",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "favorite-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sage\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "split-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = sage.datasets.bank()\n",
    "\n",
    "# Convert binary features to 0/1\n",
    "binary_cols = ['Default', 'Housing', 'Loan']\n",
    "for col in binary_cols:\n",
    "    df[col] = (df[col] == 'yes').astype(float)\n",
    "    \n",
    "# Convert education to numerical\n",
    "df['Education'].replace(\n",
    "    {'unknown': 0, 'primary': 1, 'secondary': 2, 'tertiary': 3},\n",
    "    inplace=True)\n",
    "\n",
    "# Convert month to numerical\n",
    "df['Month'].replace(\n",
    "    {'jan': 0, 'feb': 1, 'mar': 2, 'apr': 3, 'may': 4, 'jun': 5,\n",
    "     'jul': 6, 'aug': 7, 'sep': 8, 'oct': 9, 'nov': 10, 'dec': 11},\n",
    "    inplace=True)\n",
    "\n",
    "# Convert marital to one-hot\n",
    "for value in np.unique(df['Marital'].values):\n",
    "    df['Marital-{}'.format(value)] = (df['Marital'] == value).astype(float)\n",
    "df.drop(columns='Marital', inplace=True)\n",
    "\n",
    "# Convert contact to one-hot\n",
    "for value in np.unique(df['Contact'].values):\n",
    "    df['Contact-{}'.format(value)] = (df['Contact'] == value).astype(float)\n",
    "df.drop(columns='Contact', inplace=True)\n",
    "\n",
    "# Convert prev outcome to one-hot\n",
    "for value in np.unique(df['Prev Outcome'].values):\n",
    "    df['Prev Outcome-{}'.format(value)] = (df['Prev Outcome'] == value).astype(float)\n",
    "df.drop(columns='Prev Outcome', inplace=True)\n",
    "\n",
    "# Convert job to one-hot\n",
    "for value in np.unique(df['Job'].values):\n",
    "    df['Job-{}'.format(value)] = (df['Job'] == value).astype(float)\n",
    "df.drop(columns='Job', inplace=True)\n",
    "\n",
    "# Split into X, Y\n",
    "values = df.values.astype(float)\n",
    "X_cols = np.array(df.columns) != 'Success'\n",
    "X, Y = values[:, X_cols], values[:, ~X_cols]\n",
    "\n",
    "# Get feature names, groups\n",
    "feature_names = np.array(df.columns)[X_cols]\n",
    "prefixes = np.array([name.split('-')[0] for name in feature_names])\n",
    "groups = []\n",
    "group_names = []\n",
    "for prefix in np.unique(prefixes):\n",
    "    groups.append(np.where(prefixes == prefix)[0])\n",
    "    group_names.append(prefix)\n",
    "\n",
    "# Train/val/test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=123)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nonprofit-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize continuous columns\n",
    "feature_names = list(feature_names)\n",
    "num_features = len(feature_names)\n",
    "continuous_cols = ['Age', 'Balance', 'Day', 'Duration', 'Campaign',\n",
    "                   'Month', 'Prev Days', 'Prev Contacts']\n",
    "continuous_inds = [feature_names.index(col) for col in continuous_cols]\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train[:, continuous_inds])\n",
    "X_train[:, continuous_inds] = ss.transform(X_train[:, continuous_inds])\n",
    "X_val[:, continuous_inds] = ss.transform(X_val[:, continuous_inds])\n",
    "X_test[:, continuous_inds] = ss.transform(X_test[:, continuous_inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-singer",
   "metadata": {},
   "source": [
    "# Set up imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regular-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastshap_torch.utils import BaselineImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artificial-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', 6)\n",
    "model = torch.load('../models/bank_model.pt').eval().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elect-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up baseline\n",
    "baseline = np.zeros((1, num_features))\n",
    "\n",
    "# Determine values for continuous features\n",
    "for col in continuous_cols:\n",
    "    if col == 'Month':\n",
    "        continue\n",
    "    ind = feature_names.index(col)\n",
    "    baseline[0, ind] = np.mean(X_train[:, ind])\n",
    "    \n",
    "# Determine values for binary features\n",
    "for col in binary_cols:\n",
    "    ind = feature_names.index(col)\n",
    "    baseline[0, ind] = (np.mean(X_train[:, ind]) > 0.5)\n",
    "    \n",
    "# Determine values for numerical features\n",
    "for col in ('Education', 'Month'):\n",
    "    ind = feature_names.index(col)\n",
    "    values, counts = np.unique(X_train[:, ind], return_counts=True)\n",
    "    baseline[0, ind] = values[np.argmax(counts)]\n",
    "    \n",
    "# Determine values for one-hot features\n",
    "unique_prefixes, prefix_counts = np.unique(prefixes, return_counts=True)\n",
    "repeat_prefixes = unique_prefixes[prefix_counts > 1]\n",
    "for prefix in repeat_prefixes:\n",
    "    inds = np.where(prefixes == prefix)[0]\n",
    "    max_ind = np.argmax(np.mean(X_train[:, inds], axis=0))\n",
    "    baseline[0, inds[max_ind]] = 1\n",
    "\n",
    "# Set up imputer\n",
    "imputer = BaselineImputer(model, baseline, groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-gather",
   "metadata": {},
   "source": [
    "# FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "addressed-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastshap_torch import FastSHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-payroll",
   "metadata": {},
   "source": [
    "# Test samples number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial-workshop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00426090\n",
      "Best val loss = 0.00064245\n",
      "Best val loss = 0.00007975\n",
      "Best val loss = 0.00007976\n",
      "Best val loss = 0.00007906\n",
      "Best val loss = 0.00007915\n",
      "Best val loss = 0.00007931\n"
     ]
    }
   ],
   "source": [
    "for n_samples in (1, 4, 16, 32, 48, 64, 96):\n",
    "    # Set up explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, len(groups))).to(device)\n",
    "\n",
    "    # Set up FastSHAP wrapper\n",
    "    fastshap = FastSHAP(explainer, imputer, normalization='additive', link=nn.Sigmoid())\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        X_train,\n",
    "        X_val[:500],\n",
    "        batch_size=32,\n",
    "        num_samples=n_samples,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=0,\n",
    "        paired_sampling=False,\n",
    "        validation_samples=128,\n",
    "        validation_seed=123,\n",
    "        verbose=False)\n",
    "\n",
    "    # Print performance\n",
    "    print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    modifier = 'samples={}'.format(n_samples)\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, '../models/bank_baseline_explainer {} nopenalty.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "controversial-mercury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00063131\n",
      "Best val loss = 0.00007931\n",
      "Best val loss = 0.00007888\n",
      "Best val loss = 0.00007912\n",
      "Best val loss = 0.00007908\n",
      "Best val loss = 0.00007881\n"
     ]
    }
   ],
   "source": [
    "for n_samples in (4, 16, 32, 48, 64, 96):\n",
    "    # Set up explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, len(groups))).to(device)\n",
    "\n",
    "    # Set up FastSHAP wrapper\n",
    "    fastshap = FastSHAP(explainer, imputer, normalization='additive', link=nn.Sigmoid())\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        X_train,\n",
    "        X_val[:500],\n",
    "        batch_size=32,\n",
    "        num_samples=n_samples,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=0,\n",
    "        paired_sampling=True,\n",
    "        validation_samples=128,\n",
    "        validation_seed=123,\n",
    "        verbose=False)\n",
    "\n",
    "    # Print performance\n",
    "    print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    modifier = 'paired_samples={}'.format(n_samples)\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, '../models/bank_baseline_explainer {} nopenalty.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-campbell",
   "metadata": {},
   "source": [
    "# Test other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "temporal-distance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00007954\n"
     ]
    }
   ],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, len(groups))).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, imputer, normalization='additive', link=nn.Sigmoid())\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_val[:500],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=123,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nopenalty'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/bank_baseline_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "square-insight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00006845\n"
     ]
    }
   ],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, len(groups))).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, imputer, normalization=None, link=nn.Sigmoid())\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_val[:500],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0.1,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=123,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nonormalization'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/bank_baseline_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "simple-still",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00006952\n"
     ]
    }
   ],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, len(groups))).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, imputer, normalization=None, link=nn.Sigmoid())\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train,\n",
    "    X_val[:500],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=123,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nopenalty nonormalization'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/bank_baseline_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-diving",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
