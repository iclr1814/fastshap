{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daily-northern",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "humanitarian-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "listed-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    *shap.datasets.adult(), test_size=0.2, random_state=7)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "religious-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network pre-processing\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "Y_train_oh = enc.fit_transform(np.expand_dims(Y_train, -1))\n",
    "Y_val_oh = enc.fit_transform(np.expand_dims(Y_val, -1))\n",
    "Y_test_oh = enc.transform(np.expand_dims(Y_test, -1))\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_train_std = ss.transform(X_train)\n",
    "X_val_std = ss.transform(X_val)\n",
    "X_test_std = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-faculty",
   "metadata": {},
   "source": [
    "# Set up imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "quiet-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fastshap_torch\n",
    "from fastshap_torch import Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bizarre-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda', 2)\n",
    "surrogate = torch.load('../models/census_surrogate.pt').eval().to(device)\n",
    "num_features = X_train.shape[1]\n",
    "surr = Surrogate(surrogate, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-temperature",
   "metadata": {},
   "source": [
    "# FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rocky-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastshap_torch import FastSHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-assistant",
   "metadata": {},
   "source": [
    "# Test samples number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smaller-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00485420\n",
      "Best val loss = 0.00066544\n",
      "Best val loss = 0.00065956\n",
      "Best val loss = 0.00065865\n",
      "Best val loss = 0.00065339\n",
      "Best val loss = 0.00065589\n",
      "Best val loss = 0.00065450\n"
     ]
    }
   ],
   "source": [
    "for n_samples in (1, 4, 16, 32, 48, 64, 96):\n",
    "    # Set up explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP wrapper\n",
    "    fastshap = FastSHAP(explainer, surr, normalization='additive', link=nn.Softmax(dim=-1))\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        X_train_std,\n",
    "        X_val_std[:100],\n",
    "        batch_size=32,\n",
    "        num_samples=n_samples,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=0,\n",
    "        paired_sampling=False,\n",
    "        validation_samples=128,\n",
    "        validation_seed=0,\n",
    "        verbose=False)\n",
    "\n",
    "    # Print performance\n",
    "    print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    modifier = 'samples={}'.format(n_samples)\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, '../models/census_explainer {} nopenalty.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fixed-trial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00065687\n",
      "Best val loss = 0.00065401\n",
      "Best val loss = 0.00065606\n",
      "Best val loss = 0.00065294\n",
      "Best val loss = 0.00065200\n",
      "Best val loss = 0.00065038\n"
     ]
    }
   ],
   "source": [
    "for n_samples in (4, 16, 32, 48, 64, 96):\n",
    "    # Set up explainer model\n",
    "    explainer = nn.Sequential(\n",
    "        nn.Linear(num_features, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "    # Set up FastSHAP wrapper\n",
    "    fastshap = FastSHAP(explainer, surr, normalization='additive', link=nn.Softmax(dim=-1))\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        X_train_std,\n",
    "        X_val_std[:100],\n",
    "        batch_size=32,\n",
    "        num_samples=n_samples,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=0,\n",
    "        paired_sampling=True,\n",
    "        validation_samples=128,\n",
    "        validation_seed=0,\n",
    "        verbose=False)\n",
    "\n",
    "    # Print performance\n",
    "    print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    modifier = 'paired_samples={}'.format(n_samples)\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, '../models/census_explainer {} nopenalty.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-opera",
   "metadata": {},
   "source": [
    "# Test other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reflected-maine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00065215\n"
     ]
    }
   ],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, surr, normalization='additive', link=nn.Softmax(dim=-1))\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train_std,\n",
    "    X_val_std[:100],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=0,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nopenalty'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/census_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "whole-subdivision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00051005\n"
     ]
    }
   ],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, surr, normalization=None, link=nn.Softmax(dim=-1))\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train_std,\n",
    "    X_val_std[:100],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0.1,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=0,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nonormalization'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/census_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "freelance-sunday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val loss = 0.00049677\n"
     ]
    }
   ],
   "source": [
    "# Set up explainer model\n",
    "explainer = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2 * num_features)).to(device)\n",
    "\n",
    "# Set up FastSHAP wrapper\n",
    "fastshap = FastSHAP(explainer, surr, normalization=None, link=nn.Softmax(dim=-1))\n",
    "\n",
    "# Train\n",
    "fastshap.train(\n",
    "    X_train_std,\n",
    "    X_val_std[:100],\n",
    "    batch_size=32,\n",
    "    num_samples=32,\n",
    "    max_epochs=200,\n",
    "    eff_lambda=0,\n",
    "    paired_sampling=True,\n",
    "    validation_samples=128,\n",
    "    validation_seed=0,\n",
    "    verbose=False)\n",
    "\n",
    "# Print performance\n",
    "print('Best val loss = {:.8f}'.format(min(fastshap.loss_list)))\n",
    "\n",
    "# Save model\n",
    "modifier = 'nopenalty nonormalization'\n",
    "explainer.cpu()\n",
    "torch.save(explainer, '../models/census_explainer {}.pt'.format(modifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-alpha",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
